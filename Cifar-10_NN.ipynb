{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf0ae80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import random\n",
    "import skimage.transform as ski\n",
    "from scipy.stats import multivariate_normal\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "import keras\n",
    "\n",
    "\n",
    "def class_acc(pred,gt):     #Y=gt are truth labels, and pred are predicted labes\n",
    "    matching_values = 0\n",
    "    for index in range(len(gt)-1):\n",
    "        if(pred[index]==gt[index]):\n",
    "            matching_values = matching_values + 1\n",
    "    acc = (((matching_values)/(len(gt))))  #Percent\n",
    "    return acc\n",
    "\n",
    "def cifar10_classifier_random(X):\n",
    "    Y = []  #Labels\n",
    "    for image in X:  #For each image lets guess its label\n",
    "        random_number = random.randint(0,9)\n",
    "        Y.append(random_number)\n",
    "    Y = np.array(Y)\n",
    "    return Y\n",
    "\n",
    "def cifar10_classifier_1nn(x,trdata,trlabels):  #x is testdat\n",
    "\n",
    "    distances = np.sum(np.abs(trdata-x), axis=1)  #Get the distance of each image to test_image x\n",
    "    return trlabels[np.argmin(distances)]              #Return images label which has the smallest distance to test image x\n",
    "\n",
    "def divide_to_classes(Y):\n",
    "    airplane = np.where(Y == 0)\n",
    "    automobile = np.where(Y == 1)\n",
    "    bird = np.where(Y == 2)\n",
    "    cat = np.where(Y == 3)\n",
    "    deer = np.where(Y == 4)\n",
    "    dog = np.where(Y == 5)\n",
    "    frog = np.where(Y == 6)\n",
    "    horse = np.where(Y == 7)\n",
    "    ship = np.where(Y == 8)\n",
    "    truck = np.where(Y == 9)\n",
    "    return airplane,automobile,bird,cat,deer,dog,frog,horse,ship,truck\n",
    "\n",
    "\n",
    "def cifar10_color(X):\n",
    "    Xp = []\n",
    "    for image in X:\n",
    "        Xp.append(np.squeeze(ski.resize(image, (1,1))))\n",
    "\n",
    "    return np.squeeze(Xp)\n",
    "\n",
    "def cifar10_2x2_color(X):\n",
    "    Xp = []\n",
    "    for image in X:\n",
    "        Xp.append(np.squeeze(ski.resize(image, (2, 2))))\n",
    "    print(np.squeeze(Xp).shape)\n",
    "    return np.squeeze(Xp)\n",
    "\n",
    "def cifar10_NxN_color(X):\n",
    "    Xp = []\n",
    "    N = 4\n",
    "    for image in X:\n",
    "        Xp.append(np.squeeze(ski.resize(image, (N, N))))\n",
    "\n",
    "    return np.squeeze(Xp)\n",
    "\n",
    "def normal_dist(x , mu, sigma):\n",
    "    prob_density = (1 / np.sqrt(2 * np.pi * sigma)) * np.exp(-1 / (2 * sigma) * (x - mu) ** 2)\n",
    "    return prob_density\n",
    "\n",
    "\n",
    "def cifar_10_naivebayes_learn(Xp, Y):\n",
    "    mu_array = []\n",
    "    sigma_array = []\n",
    "    priori_array = []\n",
    "    for class_indexes in divide_to_classes(Y):\n",
    "        mu = np.mean(Xp[class_indexes], axis=0)\n",
    "        mu_array.append(np.squeeze(mu))\n",
    "        sigma = np.var(Xp[class_indexes], axis=0)\n",
    "        sigma_array.append(np.squeeze(sigma))\n",
    "        priori_array.append((len(Xp[class_indexes])) / (len(Xp)))\n",
    "\n",
    "    return np.array(mu_array), np.array(sigma_array), np.array(priori_array)\n",
    "\n",
    "def cifar10_classifier_naivebayes(x, mu, sigma, p):  #ONE IMAGE AT THE TIME\n",
    "    priori_sum = sum(p)\n",
    "    p_gaussian = np.squeeze(normal_dist(x, mu, sigma)) #3 gaussian distriputions\n",
    "    dim = np.ndim(p_gaussian.shape)\n",
    "    posterior_numerators = np.squeeze(p_gaussian[ :,0] * p_gaussian[ :,1] * p_gaussian[ :,2] * p)\n",
    "    posterior_denumerator = sum(p_gaussian[ :,0]) * sum(p_gaussian[ :,1]) * sum(p_gaussian[ :,2]) * priori_sum\n",
    "    class_probabilities = posterior_numerators/posterior_denumerator\n",
    "\n",
    "    return np.argmax(class_probabilities)\n",
    "\n",
    "def cifar_10_bayes_learn(Xf, Y):\n",
    "    mu_array = []\n",
    "    cov_array = []\n",
    "    priori_array = []\n",
    "    for class_indexes in divide_to_classes(Y):\n",
    "        mu = np.mean(Xf[class_indexes], axis=0)\n",
    "        mu_array.append(np.squeeze(mu))\n",
    "        covariace = np.cov((Xf[class_indexes]).T)\n",
    "        cov_array.append(np.squeeze(covariace))\n",
    "        priori_array.append((len(Xf[class_indexes])) / (len(Xf)))\n",
    "\n",
    "    return np.array(mu_array), np.array(cov_array), np.array(priori_array)\n",
    "\n",
    "\n",
    "def cifar10_classifier_bayes(x, mu, sigma, p):\n",
    "    priori_sum = sum(p)\n",
    "    p_array = []\n",
    "    for index in range(0,10):\n",
    "        p_array.append(multivariate_normal.pdf(x, mu[index], sigma[index]))\n",
    "\n",
    "    p_gaussian = np.array(p_array)\n",
    "    posterior_numerators = p_gaussian * p\n",
    "    posterior_denumerator = sum(p_gaussian) * priori_sum\n",
    "    class_probabilities = posterior_numerators / posterior_denumerator\n",
    "\n",
    "    return np.argmax(class_probabilities)\n",
    "\n",
    "def unpickle(file):\n",
    "    with open(file, 'rb') as f:\n",
    "        dict = pickle.load(f, encoding=\"latin1\")\n",
    "    return dict\n",
    "\n",
    "\n",
    "def load_training_data(databatches):\n",
    "    X = []\n",
    "    Y = []\n",
    "    for batch in range(1, databatches+1):\n",
    "        datadict = unpickle('/Users/Simon/machine_learning/Week3/ex2/cifar-10-batches-py/data_batch_{}'.format(batch))\n",
    "        X.append(datadict[\"data\"])\n",
    "        Y.append(datadict[\"labels\"])\n",
    "    X = np.concatenate(X)\n",
    "    Y = np.concatenate(Y)\n",
    "    return X, Y\n",
    "\n",
    "#Training data\n",
    "databatches = 5  # Select from 1-5\n",
    "\n",
    "X_train, Y_train = load_training_data(databatches)\n",
    "X_train = np.array(X_train).astype(\"float32\")\n",
    "X_train = X_train.reshape(databatches*10000, 3, 32, 32).transpose(0,2,3,1).astype(\"float32\")\n",
    "Y_train = np.array(Y_train) # T_train, Labes of classes in X\n",
    "\n",
    "\n",
    "datadict = unpickle('/Users/Simon/machine_learning/Week3/ex2/cifar-10-batches-py/test_batch')\n",
    "test_X = datadict[\"data\"]\n",
    "test_X = np.array(test_X).astype(\"float32\")\n",
    "test_Y = datadict[\"labels\"]\n",
    "test_X = test_X.reshape(10000, 3, 32, 32).transpose(0,2,3,1).astype(\"float32\")\n",
    "test_Y = np.array(test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572d6267-65ed-4a96-b7f5-b07430ff03c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_vectors(Y):\n",
    "    Y_one_hot = np.empty([len(Y),10])\n",
    "    for index in range(0,10):     \n",
    "        one_hot = np.zeros((9,), dtype=int)\n",
    "        one_hot = np.insert(one_hot, index, 1)\n",
    "        class_indexes = divide_to_classes(Y)[index]\n",
    "        Y_one_hot[class_indexes] = one_hot\n",
    "        \n",
    "    return np.squeeze(Y_one_hot)\n",
    "                     \n",
    "def get_argmax(Y):\n",
    "    Y_list = []\n",
    "    for probabilities in Y:\n",
    "        Y_list.append(np.argmax(probabilities))\n",
    "    return np.array(Y_list)\n",
    "    \n",
    "    \n",
    "    \n",
    "Y_train_vector = one_hot_vectors(Y_train)\n",
    "\n",
    "X_train = keras.utils.normalize(X_train, axis=1)\n",
    "test_X = keras.utils.normalize(test_X, axis=1)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, input_shape=(32,32,3), activation='relu'))\n",
    "model.add(Dense(10, input_shape=(32,32,3), activation=tf.nn.softmax))\n",
    "keras.optimizers.SGD(lr=0.9)\n",
    "model.compile(optimizer='SGD', loss='mse', metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train_vector, epochs=100)\n",
    "\n",
    "Y_train_pred = np.squeeze(model.predict(X_train))\n",
    "Y_test_pred = np.squeeze(model.predict(test_X))\n",
    "\n",
    "# \"model.predicts\" returns probabilities for every class,\n",
    "# but we only need to get the class with largest probability\n",
    "\n",
    "Y_train_pred = get_argmax(Y_train_pred)\n",
    "Y_test_pred = get_argmax(Y_test_pred)\n",
    "\n",
    "print(f'Classication accuracy (train data): {class_acc(Y_train_pred, Y_train)}%')\n",
    "print(f'Classication accuracy (test data): {class_acc(Y_test_pred, test_Y)}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
